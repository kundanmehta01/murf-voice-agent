#!/usr/bin/env python3
"""
ğŸ¤ Complete Voice Agent - Day 23 Implementation
==================================================

This script demonstrates the complete working conversational voice agent with:
- Real-time speech transcription (AssemblyAI)
- LLM processing (Google Gemini)  
- Text-to-speech generation (Murf)
- WebSocket audio streaming
- Chat history persistence
- Complete web interface

Author: Day 23 Voice Agent Implementation
"""

import asyncio
import uvicorn
import webbrowser
import time
from services.llm import LLM_AVAILABLE
from services.tts import TTS_AVAILABLE
from services.stt import STT_AVAILABLE, _V3_OK

def show_banner():
    """Display the voice agent banner"""
    banner = """
ğŸ¤========================================================ğŸ¤
                   COMPLETE VOICE AGENT
                     Day 23 Implementation
ğŸ¤========================================================ğŸ¤

âœ… FULLY INTEGRATED FEATURES:
   
   ğŸ™ï¸  Real-time Speech-to-Text (AssemblyAI Streaming)
   ğŸ§  LLM Processing (Google Gemini with streaming)
   ğŸ”Š Text-to-Speech (Murf AI with audio streaming)
   ğŸ’¬ Chat History Persistence  
   ğŸŒ WebSocket Audio Streaming
   ğŸ“± Modern Web Interface with VU meters
   âš¡ Auto-streaming conversations
   
ğŸ¤========================================================ğŸ¤

ğŸš€ COMPLETE WORKFLOW:
   1. User speaks into microphone
   2. Audio is streamed to AssemblyAI via WebSocket
   3. Real-time transcription with turn detection
   4. Transcript sent to Gemini LLM for processing
   5. LLM response streamed in real-time
   6. Response converted to speech via Murf
   7. Audio streamed back to client
   8. Chat history automatically saved

ğŸ¤========================================================ğŸ¤
    """
    print(banner)

def check_services():
    """Check service availability"""
    print("ğŸ” CHECKING SERVICES:")
    print(f"   STT (AssemblyAI): {'âœ… Ready' if STT_AVAILABLE else 'âŒ Not Available'}")
    print(f"   STT Streaming: {'âœ… Ready' if _V3_OK else 'âŒ Not Available'}")
    print(f"   LLM (Gemini): {'âœ… Ready' if LLM_AVAILABLE else 'âŒ Not Available'}")
    print(f"   TTS (Murf): {'âœ… Ready' if TTS_AVAILABLE else 'âŒ Not Available'}")
    
    if not all([STT_AVAILABLE, LLM_AVAILABLE, TTS_AVAILABLE, _V3_OK]):
        print("\nâŒ SETUP ISSUE: Some services are not available.")
        print("   Please check your API keys in the .env file.")
        return False
    
    print("\nâœ… ALL SERVICES READY!")
    return True

def show_features():
    """Show key features"""
    features = """
ğŸ“‹ KEY FEATURES IMPLEMENTED:

ğŸ™ï¸ SPEECH INPUT:
   - Real-time microphone capture
   - 16kHz PCM audio streaming
   - WebSocket connection to AssemblyAI
   - Turn detection and end-of-speech recognition

ğŸ§  AI PROCESSING:
   - Google Gemini LLM integration
   - Streaming responses for real-time feel
   - Context-aware conversation handling
   - Chat history integration

ğŸ”Š VOICE OUTPUT:
   - Murf AI text-to-speech
   - High-quality voice synthesis
   - Audio streaming for immediate playback
   - Base64 audio streaming support

ğŸ’¬ CONVERSATION FEATURES:
   - Session-based chat history
   - Persistent conversation memory
   - Real-time transcript display
   - Turn-based conversation flow

ğŸŒ WEB INTERFACE:
   - Modern responsive design
   - VU meter visualization
   - Real-time status updates
   - Auto-stream mode for hands-free operation

âš¡ TECHNICAL HIGHLIGHTS:
   - WebSocket-based audio streaming
   - Async/await throughout
   - Error handling and fallbacks
   - Production-ready FastAPI backend
    """
    print(features)

def show_usage():
    """Show usage instructions"""
    usage = """
ğŸ¯ HOW TO USE:

1. ğŸ“± Open http://127.0.0.1:8000 in your browser
2. ğŸ¤ Allow microphone access when prompted
3. ğŸŸ¢ Click "Start Talking" to begin recording
4. ğŸ—£ï¸ Speak your question or message
5. â¸ï¸ Click "Listening... Tap to stop" to end recording
6. âš™ï¸ The agent will:
   - Transcribe your speech in real-time
   - Process with AI (Gemini)
   - Convert response to speech (Murf)
   - Stream audio back to you
7. ğŸ’¬ Chat history is automatically saved
8. âš¡ Enable "Auto-Stream" for hands-free conversation

ğŸ”§ ADVANCED FEATURES:
   - Real-time transcription with interim results
   - Turn detection for natural conversation
   - Audio chunk streaming for immediate playback
   - Session persistence across browser refreshes
   - Error handling with graceful fallbacks
    """
    print(usage)

async def main():
    """Main startup function"""
    show_banner()
    
    if not check_services():
        print("\nâŒ Cannot start - services not ready")
        return
    
    show_features()
    show_usage()
    
    print("\nğŸš€ STARTING VOICE AGENT SERVER...")
    print("ğŸ“ Server will be available at: http://127.0.0.1:8000")
    print("ğŸ¤ Make sure to allow microphone access!")
    print("â¹ï¸ Press Ctrl+C to stop the server\n")
    
    # Small delay to let user read
    await asyncio.sleep(2)
    
    # Try to open browser automatically
    try:
        print("ğŸŒ Opening browser automatically...")
        webbrowser.open("http://127.0.0.1:8000")
    except:
        print("âš ï¸ Could not auto-open browser. Please manually open http://127.0.0.1:8000")
    
    # Start the server
    try:
        config = uvicorn.Config(
            "main:app",
            host="127.0.0.1",
            port=8000,
            log_level="info"
        )
        server = uvicorn.Server(config)
        await server.serve()
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ Server stopped by user")
    except Exception as e:
        print(f"\nâŒ Server error: {e}")

if __name__ == "__main__":
    asyncio.run(main())
